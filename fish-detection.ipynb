{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkjvb11s5EJu"
   },
   "source": [
    "# Fish in Image Detection\n",
    "\n",
    "dataset: https://www.kaggle.com/datasets/slavkoprytula/aquarium-data-cots\n",
    "\n",
    "Author: 'Hal' Sterling Halberstadt\n",
    "Purpose: \n",
    "I want to make an object detection and this seemed like a difficult enough problem with a good enough dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m7ZSPy8U4_UT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers, Input, Model, callbacks, utils, callbacks, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image # for resizing images\n",
    "from IPython.display import display, HTML\n",
    "from skimage import io, color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image set resizing\n",
    "since the images in the dataset are different sizes, I am going to resize all the images beforehand so I don't need to add time resizing images in the generator \n",
    "\n",
    "The main thing is not to remove data, so that the text files are still accurate\n",
    "\n",
    "NOTE: the code used to resize the images is in a markdown cell as for you to be able to replicate even though it will not run if directly pulled as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations\n",
    "data_dir = '../Comp_Vis_Proj/aquarium'\n",
    "\n",
    "test_path = Path(data_dir+'/test/images').glob(\"*.jpg\")\n",
    "test_list = list(test_path)\n",
    "train_path = Path(data_dir+'/train/images').glob(\"*.jpg\")\n",
    "train_list = list(train_path)\n",
    "valid_path = Path(data_dir+'/valid/images').glob(\"*.jpg\")\n",
    "valid_list = list(valid_path)\n",
    "\n",
    "# image constants\n",
    "# img_size = (1024, 1024, 3)\n",
    "# img_size = (512, 512, 3)\n",
    "img_size = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python code for resizing images:\n",
    "\n",
    "note that this will pad the sides with black space to the right and bottom of the image\n",
    "\n",
    "```\n",
    "for current_list in [test_list, train_list, valid_list]:\n",
    "    for i, ID in enumerate(current_list):\n",
    "        # get image location\n",
    "        image_location = str(ID)\n",
    "        \n",
    "        with Image.open(image_location) as image: # code adapted from https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
    "            old_size = image.size  # old_size[0] is in (width, height) format\n",
    "\n",
    "            ratio = float(img_size[0])/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "            image = image.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "            new_im = Image.new(\"RGB\", (img_size[0], img_size[0]))\n",
    "            new_im.paste(image, ((img_size[0]-new_size[0])//2, (img_size[0]-new_size[1])//2))\n",
    "            \n",
    "            # new_im.show();\n",
    "            new_im.save(image_location)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to grab the file(s) with the data, I am also then going to make a generator so that I do not need to hold more than a few images in memory at a time.\n",
    "\n",
    "classes of fish associated with the dataset (pulled from the kaggle page listed above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cBN3sFXH4_Ub"
   },
   "outputs": [],
   "source": [
    "fish_classes = ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "shZkiChU2ik-"
   },
   "outputs": [],
   "source": [
    "def plot_metric(history, metric='loss'): # credit to Glenn Bruns of CSUMB, this is taken from code provided during his ML course.\n",
    "    \"\"\" Plot training and test values for a metric. \"\"\"\n",
    "    plt.figure(figsize=(4,4))\n",
    "    val_metric = 'val_'+metric\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[val_metric])\n",
    "    plt.title('model '+metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(utils.Sequence): \n",
    "    '''\n",
    "    adapted from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    '''\n",
    "    def __init__(self, list_IDs_fold, batch_size=8, \n",
    "                 dim=img_size, objs=(25, 5), n_channels=3, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.objs = objs\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs_fold\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        list_IDs = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size, *self.objs))  \n",
    "                \n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # get image location\n",
    "            image_location = str(ID)\n",
    "            # print(image_location)\n",
    "            # shift to fit correct location\n",
    "            text_location = str(ID).replace(\"\\\\images\\\\\", \"\\\\labels\\\\\").replace(\".jpg\", \".txt\")\n",
    "            \n",
    "            num_coords = 0\n",
    "            with open(text_location) as f:\n",
    "                coord_txt = f.readline().rstrip()\n",
    "                # print(f\"\\\"{coord_txt}\\\"\")\n",
    "                if coord_txt == \"\":\n",
    "                    y[i] = [-1.0, -1.0, -1.0, -1.0, -1.0]\n",
    "                else:\n",
    "                    y[i] = [float(i) for i in coord_txt.split()]\n",
    "                # num_coords += 1\n",
    "                \n",
    "            # size halved in width and height to be possible to do.\n",
    "            X[i] = load_img(image_location).resize(img_size[:2])\n",
    "            # X[i] = load_img(image_location).resize((1024, 1024))\n",
    "                    \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generators\n",
    "test_generator = DataGenerator(test_list)\n",
    "train_generator = DataGenerator(train_list)\n",
    "valid_generator = DataGenerator(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "nodes = 8\n",
    "_activation = 'relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img_input (InputLayer)      [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 107, 107, 8)      67532     \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 8, 8, 8)          80072     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 8)             0         \n",
      "                                                                 \n",
      " separable_conv1d (Separable  (None, 25, 8)            392       \n",
      " Conv1D)                                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25, 8)             72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25, 16)            144       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25, 5)             85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148,297\n",
      "Trainable params: 148,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((img_size), name=\"img_input\")\n",
    "\n",
    "x = layers.SeparableConv2D(nodes, (150,150), activation=_activation)(inputs)\n",
    "x = layers.SeparableConv2D(nodes, (100,100), activation=_activation)(x)\n",
    "\n",
    "x = layers.Reshape((8*8, nodes))(x)\n",
    "\n",
    "x = layers.SeparableConv1D(8, (40), activation=_activation)(x)\n",
    "\n",
    "x = layers.Dense(nodes, activation=_activation)(x)\n",
    "x = layers.Dense(nodes*2, activation=_activation)(x)\n",
    "\n",
    "x = layers.Dense(5, activation=_activation)(x)\n",
    "\n",
    "model = Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create a loss function that is able to have the weights of correct fish Identification be able to be weighed differently than "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_monitor = 'val_loss'\n",
    "_patience = 2\n",
    "_verbose = 0\n",
    "min_increase = 0.02\n",
    "use_best = False\n",
    "start_EarlyStopping = 3\n",
    "scheduler_rate = -.1\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(scheduler_rate)\n",
    "\n",
    "my_callbacks = [\n",
    "    callbacks.EarlyStopping(monitor=_monitor,\n",
    "                            min_delta=0,\n",
    "                            patience=_patience,\n",
    "                            verbose=_verbose,\n",
    "                            baseline=min_increase,\n",
    "                            restore_best_weights=use_best,\n",
    "                            start_from_epoch=start_EarlyStopping),\n",
    "    ReduceLROnPlateau(monitor=_monitor,\n",
    "                      factor=0.1,\n",
    "                      patience=_patience+1,\n",
    "                      verbose=_verbose,\n",
    "                      min_delta=0.0001,\n",
    "                      cooldown=0,\n",
    "                      min_lr=0),\n",
    "    LearningRateScheduler(scheduler, \n",
    "                          verbose=_verbose)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/100\n",
      "56/56 [==============================] - 472s 8s/step - loss: 407210.2188 - accuracy: 0.5045 - val_loss: 2.1808 - val_accuracy: 0.6333 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/100\n",
      "44/56 [======================>.......] - ETA: 1:41 - loss: 2.3174 - accuracy: 0.6534"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='RMSprop', loss='mean_squared_error',  metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=valid_generator, # Note to self valid replaced test due to it being added later\n",
    "                    callbacks=my_callbacks,\n",
    "                    epochs=100, \n",
    "                    verbose=_verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have trained the model I want to try it on entirely new data and see how it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(test_generator)\n",
    "model.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am _ about how this turned out, I think I need to try doing _ and see how that might affect the accuracy."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "activity-recognition-cnn-gold.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
